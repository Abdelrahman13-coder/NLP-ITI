{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**\n",
    "labeled datasset collected from twitter\n",
    "\n",
    "**Objective**\n",
    "classify tweets containing hate speech from other tweets.\n",
    "0 -> no hate speech\n",
    "1 -> contains hate speech\n",
    "\n",
    "**Total Estimated Time = 90 Mins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install unidecode\n",
    "# !pip install word2number\n",
    "# !pip install contractions\n",
    "# !python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
    "\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "import unidecode\n",
    "import contractions\n",
    "from word2number import w2n\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         @user when a father is dysfunctional and is s...\n",
       "1        @user @user thanks for #lyft credit i can't us...\n",
       "2                                      bihday your majesty\n",
       "3        #model   i love u take with u all the time in ...\n",
       "4                   factsguide: society now    #motivation\n",
       "                               ...                        \n",
       "31957    ate @user isz that youuu?ðððððð...\n",
       "31958      to see nina turner on the airwaves trying to...\n",
       "31959    listening to sad songs on a monday morning otw...\n",
       "31960    @user #sikh #temple vandalised in in #calgary,...\n",
       "31961                     thank you @user for you follow  \n",
       "Name: tweet, Length: 31962, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('dataset.csv')\n",
    "tweets['tweet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "label    0\n",
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    31962\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- show samples of data texts to find out required preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      @user when a father is dysfunctional and is s...\n",
       "1     @user @user thanks for #lyft credit i can't us...\n",
       "2                                   bihday your majesty\n",
       "3     #model   i love u take with u all the time in ...\n",
       "4                factsguide: society now    #motivation\n",
       "5     [2/2] huge fan fare and big talking before the...\n",
       "6      @user camping tomorrow @user @user @user @use...\n",
       "7     the next school year is the year for exams.ð...\n",
       "8     we won!!! love the land!!! #allin #cavs #champ...\n",
       "9      @user @user welcome here !  i'm   it's so #gr...\n",
       "10     â #ireland consumer price index (mom) climb...\n",
       "11    we are so selfish. #orlando #standwithorlando ...\n",
       "12    i get to see my daddy today!!   #80days #getti...\n",
       "13    @user #cnn calls #michigan middle school 'buil...\n",
       "14    no comment!  in #australia   #opkillingbay #se...\n",
       "15    ouch...junior is angryð#got7 #junior #yugyo...\n",
       "16    i am thankful for having a paner. #thankful #p...\n",
       "17                               retweet if you agree! \n",
       "18    its #friday! ð smiles all around via ig use...\n",
       "19    as we all know, essential oils are not made of...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['tweet'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check dataset balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(tweets['label']).set_title('Distribution of Class');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>â #ireland consumer price index (mom) climb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>we are so selfish. #orlando #standwithorlando ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>i get to see my daddy today!!   #80days #getti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #cnn calls #michigan middle school 'buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>no comment!  in #australia   #opkillingbay #se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  label                                              tweet\n",
       "0    1      0   @user when a father is dysfunctional and is s...\n",
       "1    2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2    3      0                                bihday your majesty\n",
       "3    4      0  #model   i love u take with u all the time in ...\n",
       "4    5      0             factsguide: society now    #motivation\n",
       "5    6      0  [2/2] huge fan fare and big talking before the...\n",
       "6    7      0   @user camping tomorrow @user @user @user @use...\n",
       "7    8      0  the next school year is the year for exams.ð...\n",
       "8    9      0  we won!!! love the land!!! #allin #cavs #champ...\n",
       "9   10      0   @user @user welcome here !  i'm   it's so #gr...\n",
       "10  11      0   â #ireland consumer price index (mom) climb...\n",
       "11  12      0  we are so selfish. #orlando #standwithorlando ...\n",
       "12  13      0  i get to see my daddy today!!   #80days #getti...\n",
       "13  14      1  @user #cnn calls #michigan middle school 'buil...\n",
       "14  15      1  no comment!  in #australia   #opkillingbay #se..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25569\n",
      "6393\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train, y_test = train_test_split(tweets['tweet'],tweets['label'],\n",
    "                                                   test_size=0.2, random_state=42,\n",
    "                                                   stratify=tweets['label'])\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(X_train, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cleaning and Preprocessing are:\n",
    "    - 1 Remove the @ and #\n",
    "    - 2 \n",
    "    - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern = re.compile(r'[\\@|\\#]\\w+ | ^\\s+ | \\W | \\w\\!+')\n",
    "# tweets['clean_tweets'] = tweets['tweet'].replace(pattern,'')\n",
    "\n",
    "def process_tweet(tweet):\n",
    "    return \" \".join(re.sub(\"([\\@][A-Za-z0-9]+)|([^0-9A-Za-z \\t])\", \" \",tweet.lower()).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets['clean_tweets'] = tweets['tweet'].apply(process_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets['tweets'].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>â #ireland consumer price index (mom) climb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>we are so selfish. #orlando #standwithorlando ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>i get to see my daddy today!!   #80days #getti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #cnn calls #michigan middle school 'buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>no comment!  in #australia   #opkillingbay #se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  label                                              tweet\n",
       "0    1      0   @user when a father is dysfunctional and is s...\n",
       "1    2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2    3      0                                bihday your majesty\n",
       "3    4      0  #model   i love u take with u all the time in ...\n",
       "4    5      0             factsguide: society now    #motivation\n",
       "5    6      0  [2/2] huge fan fare and big talking before the...\n",
       "6    7      0   @user camping tomorrow @user @user @user @use...\n",
       "7    8      0  the next school year is the year for exams.ð...\n",
       "8    9      0  we won!!! love the land!!! #allin #cavs #champ...\n",
       "9   10      0   @user @user welcome here !  i'm   it's so #gr...\n",
       "10  11      0   â #ireland consumer price index (mom) climb...\n",
       "11  12      0  we are so selfish. #orlando #standwithorlando ...\n",
       "12  13      0  i get to see my daddy today!!   #80days #getti...\n",
       "13  14      1  @user #cnn calls #michigan middle school 'buil...\n",
       "14  15      1  no comment!  in #australia   #opkillingbay #se..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.apply(process_tweet)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    return \" \".join(re.sub(\"([\\@][A-Za-z0-9]+)|([^0-9A-Za-z \\t])\", \" \",tweet.lower()).split())\n",
    " \n",
    "def text_preprocessing(text):\n",
    "    text = process_tweet(text)\n",
    "\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    text = soup.get_text(separator=\" \")\n",
    " \n",
    "    text = text.strip()\n",
    "    text =  \" \".join(text.split())\n",
    " \n",
    "    text = unidecode.unidecode(text)\n",
    " \n",
    "    text = contractions.fix(text)\n",
    " \n",
    "    text = text.lower()\n",
    " \n",
    "    doc = nlp(text) \n",
    "    clean_text = []\n",
    "\n",
    "    for token in doc:\n",
    "        flag = True\n",
    "        edit = token.text\n",
    "\n",
    "        if token.is_stop and token.pos_ != 'NUM': \n",
    "            flag = False\n",
    "#         if token.pos_ == 'PUNCT' and flag == True: \n",
    "#             flag = False\n",
    "        if token.pos_ == 'SYM' and flag == True: \n",
    "            flag = False\n",
    "        if (token.pos_ == 'NUM' or token.text.isnumeric()) \\\n",
    "        and flag == True:\n",
    "            flag = False\n",
    "        if token.pos_ == 'NUM' and flag == True:\n",
    "            edit = w2n.word_to_num(token.text)\n",
    "        elif token.lemma_ != \"-PRON-\" and flag == True:\n",
    "            edit = token.lemma_\n",
    "        if edit != \"\" and flag == True:\n",
    "            clean_text.append(edit)        \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.apply(lambda x : \" \".join(text_preprocessing(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26247           order black amp sexy s collection cantwait\n",
       "13681               s s m tell andrew jackson cantankerous\n",
       "25676                   video hateful liberal america crap\n",
       "14544    monaco podium time guy maybe mclarenhonda cana...\n",
       "25411    wow open amateur hour fox golf people walk com...\n",
       "                               ...                        \n",
       "15438    scratch tweet jo sorry borrow box tell complement\n",
       "29797                   special moment family familia ness\n",
       "15613                          kudo compliant itaxnirahisi\n",
       "1955     streetautopia attack bull game 3d think head c...\n",
       "9371                                                    pm\n",
       "Name: tweet, Length: 25569, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stemmeing(text):\n",
    "#     stemmed_words = [stemmer.stem(word) for word in text]\n",
    "#     return \" \".join(re.sub(\"([\\@|\\#][A-Za-z0-9]+)|([^0-9A-Za-z \\t])\", \" \",tweet.lower()).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.apply(lambda x : \" \".join(text_preprocessing(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If it takes 60 Mins till here, you are doing Great** <br>\n",
    "**If not! You also are doing Great**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['tweet'] = tweets['tweet'].apply(lambda x : \" \".join(text_preprocessing(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "vec = CountVectorizer()\n",
    "clf = LogisticRegression()\n",
    "pipe = make_pipeline(vec, clf)\n",
    "pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      5945\n",
      "           1       0.86      0.54      0.67       448\n",
      "\n",
      "    accuracy                           0.96      6393\n",
      "   macro avg       0.91      0.77      0.82      6393\n",
      "weighted avg       0.96      0.96      0.96      6393\n",
      "\n",
      "accuracy: 0.962\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def print_report(pipe, X_test, y_test):\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    report = metrics.classification_report(y_test, y_pred)\n",
    "    print(report)\n",
    "    print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
    "\n",
    "print_report(pipe, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhancement\n",
    "\n",
    "- Using different N-grams\n",
    "- Using different text representation technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(analyzer='char_wb', max_df=0.3, min_df=0.01,\n",
       "                                 ngram_range=(3, 5))),\n",
       "                ('linearsvc', LinearSVC())])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vec = TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=.01, max_df=.3)\n",
    "# clf = LinearSVC()\n",
    "# pipe_tfidf = make_pipeline(vec, clf)\n",
    "# pipe_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      5945\n",
      "           1       0.79      0.49      0.61       448\n",
      "\n",
      "    accuracy                           0.96      6393\n",
      "   macro avg       0.88      0.74      0.79      6393\n",
      "weighted avg       0.95      0.96      0.95      6393\n",
      "\n",
      "accuracy: 0.955\n"
     ]
    }
   ],
   "source": [
    "# print_report(pipe_tfidf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_longest_text(texts):\n",
    "    longest_input = 0\n",
    "    for text in texts:\n",
    "        text_len= len(text.split())\n",
    "        longest_input = max(longest_input, text_len)\n",
    "    return longest_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_input = get_longest_text(tweets['tweet'])\n",
    "longest_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 31962/31962 [00:29<00:00, 1100.09it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data_emb = np.zeros((len(tweets['tweet']), longest_input, 300))\n",
    "\n",
    "for i, text in enumerate(tqdm(nlp.pipe(tweets['tweet']), total=len(tweets['tweet']))):\n",
    "#     print(text)\n",
    "#     print(type(text))\n",
    "    for j, token in enumerate(text):\n",
    "        #         print(token)\n",
    "#         print(type(token))\n",
    "        data_emb[i, j] = token.vector\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# define the network\n",
    "inputs = tf.keras.layers.Input((longest_input, 300))\n",
    "reshaped = tf.keras.layers.Reshape((longest_input, 300, 1))(inputs)\n",
    "\n",
    "\n",
    "filters = [2, 3, 4]\n",
    "\n",
    "# define the conv net\n",
    "conv_1 = tf.keras.layers.Conv2D(100, (filters[0], 300), activation='relu')(reshaped)\n",
    "conv_2 = tf.keras.layers.Conv2D(100, (filters[1], 300), activation='relu')(reshaped)\n",
    "conv_3 = tf.keras.layers.Conv2D(100, (filters[2], 300), activation='relu')(reshaped)\n",
    "\n",
    "# define max-pooling\n",
    "pool_1 = tf.keras.layers.MaxPooling2D((longest_input - filters[0] + 1, 1), strides=(1,1))(conv_1)\n",
    "pool_2 = tf.keras.layers.MaxPooling2D((longest_input - filters[1] + 1, 1), strides=(1,1))(conv_2)\n",
    "pool_3 = tf.keras.layers.MaxPooling2D((longest_input - filters[2] + 1, 1), strides=(1,1))(conv_3)\n",
    "\n",
    "# concatenate the convs\n",
    "merged_tensor = tf.keras.layers.concatenate([pool_1, pool_2, pool_3], axis=1)\n",
    "\n",
    "# now flatten them and add a dense layer\n",
    "flatten = tf.keras.layers.Flatten()(merged_tensor)\n",
    "\n",
    "# add a dense layer\n",
    "clf = tf.keras.layers.Dense(100, activation='relu')(flatten)\n",
    "\n",
    "# add final output\n",
    "clf = tf.keras.layers.Dense(1, activation='sigmoid')(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 37, 300)]    0           []                               \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 37, 300, 1)   0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 36, 1, 100)   60100       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 35, 1, 100)   90100       ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 34, 1, 100)   120100      ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 1, 1, 100)    0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 100)   0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 100)   0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 3, 1, 100)    0           ['max_pooling2d[0][0]',          \n",
      "                                                                  'max_pooling2d_1[0][0]',        \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 300)          0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 100)          30100       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1)            101         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 300,501\n",
      "Trainable params: 300,501\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model = tf.keras.models.Model(inputs, clf)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 37, 300])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydot --user\n",
    "# !pip install graphviz --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model, show_shapes=False, show_layer_names=True,\n",
    "    rankdir='TB', expand_nested=False, dpi=96\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's split the data and train our model\n",
    "X_train,X_test, y_train, y_test = train_test_split(data_emb,tweets['label'],\n",
    "                                                   test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.70077997,  0.12019   ,  0.063648  , ..., -0.52301002,\n",
       "         -0.81168002,  0.15805   ],\n",
       "        [-0.74085999,  0.096661  , -0.12616   , ..., -0.012397  ,\n",
       "          0.39416999, -0.029652  ],\n",
       "        [-0.62774003,  0.39978001, -0.47624001, ..., -0.10292   ,\n",
       "          0.083312  ,  0.13992   ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[-0.84258002, -0.26696   ,  0.68818003, ...,  0.42965999,\n",
       "         -0.27226999,  0.041207  ],\n",
       "        [-0.73922998, -0.030888  ,  0.2376    , ...,  0.12554   ,\n",
       "          0.0076992 , -0.080382  ],\n",
       "        [-0.76533002,  0.16752   , -0.15765999, ...,  0.10278   ,\n",
       "         -0.77441001, -0.070121  ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[-0.68687999,  0.52524   ,  0.11867   , ..., -0.49458   ,\n",
       "         -0.47955   ,  0.30160001],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.68687999,  0.52524   ,  0.11867   , ..., -0.49458   ,\n",
       "         -0.47955   ,  0.30160001],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.62299001, -0.31332001, -0.014659  , ..., -0.48258001,\n",
       "          0.049814  , -0.40219   ],\n",
       "        [-0.62766999,  0.082972  , -0.033978  , ..., -0.047645  ,\n",
       "          0.54408002,  0.14336   ],\n",
       "        [-0.74829   ,  0.53029001, -0.2228    , ..., -0.40114   ,\n",
       "          0.24068999,  0.4691    ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.84140003,  0.59628999,  0.2473    , ..., -0.29299   ,\n",
       "          0.035984  , -0.48710001],\n",
       "        [-0.75994998, -0.59446001,  0.23483001, ...,  0.68440002,\n",
       "         -0.22804999, -0.002403  ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[-0.74829   ,  0.53029001, -0.2228    , ..., -0.40114   ,\n",
       "          0.24068999,  0.4691    ],\n",
       "        [-0.64832997, -0.48908001, -0.57797998, ...,  0.020801  ,\n",
       "         -0.53583997,  0.065557  ],\n",
       "        [-0.61251003,  0.2665    , -0.43900999, ...,  0.0014679 ,\n",
       "          0.45464   ,  0.23736   ],\n",
       "        ...,\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "800/800 [==============================] - 9s 12ms/step - loss: 0.0000e+00 - acc: 0.9301\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0000e+00 - acc: 0.9301\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.0000e+00 - acc: 0.9301\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.0000e+00 - acc: 0.9301\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.0000e+00 - acc: 0.9301\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 11s 13ms/step - loss: 0.0000e+00 - acc: 0.9301\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.0000e+00 - acc: 0.9301\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 8s 10ms/step - loss: 0.0000e+00 - acc: 0.9301\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 9s 11ms/step - loss: 0.0000e+00 - acc: 0.9301\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 10s 12ms/step - loss: 0.0000e+00 - acc: 0.9301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18ce66f3370>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,  y_train,epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 1s 3ms/step - loss: 0.0000e+00 - acc: 0.9287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0, 0.9286719560623169]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
